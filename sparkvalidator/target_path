
from sparkvalidator.functions import *
from sparkvalidator.sampler import *
import pyspark
spark = pyspark.sql.SparkSession.builder.appName('demo').getOrCreate()
df = spark.read.option('header', 'true').csv('data/walmart_stock.csv')
df = random_sampling(df, 0, False, 0.1)
df = df.select(df['Open'].cast('float'), df['High'].cast('float'), df['Low'].cast('float'), df['Close'].cast('float'))
entryCount = count(df)
print('total number of entries: ', entryCount)
HighPriceDf = df.select(df['High'])
maxPriceDf = HighPriceDf.groupBy()
maxPriceDf = max(maxPriceDf)
maxPriceDf.show()
df = df.rdd.map((lambda x: ((x[1] - x[2]), (x[3] - x[0])))).toDF(['max_price_fluctuation', 'final_price_change'])
df.show()
fluctuationDf = df.select(df['max_price_fluctuation'])
fluctuationDf = fluctuationDf.groupBy()
fluctuationDf = fluctuationDf.avg()
fluctuationDf.show()
